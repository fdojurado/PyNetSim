{"cells":[{"cell_type":"code","execution_count":694,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:08.068793Z","iopub.status.busy":"2023-11-13T18:31:08.068197Z","iopub.status.idle":"2023-11-13T18:31:09.662200Z","shell.execute_reply":"2023-11-13T18:31:09.660628Z","shell.execute_reply.started":"2023-11-13T18:31:08.068762Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import lr_scheduler\n","from tqdm import tqdm\n","import torch.nn as nn\n","import gc\n","import torch\n","from numpy import array\n","import numpy as np  # linear algebra\n","import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."]},{"cell_type":"markdown","metadata":{},"source":["Lets load the CSV file into a Pandas dataframe."]},{"cell_type":"code","execution_count":695,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:09.665501Z","iopub.status.busy":"2023-11-13T18:31:09.664984Z","iopub.status.idle":"2023-11-13T18:31:12.401582Z","shell.execute_reply":"2023-11-13T18:31:12.400331Z","shell.execute_reply.started":"2023-11-13T18:31:09.665472Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv('/Users/fernando/PyNetSim/tutorials/surrogate/data/data.csv')"]},{"cell_type":"markdown","metadata":{},"source":["Lets check the shape of the dataframe.\n"]},{"cell_type":"code","execution_count":696,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:12.403211Z","iopub.status.busy":"2023-11-13T18:31:12.402948Z","iopub.status.idle":"2023-11-13T18:31:12.409614Z","shell.execute_reply":"2023-11-13T18:31:12.408188Z","shell.execute_reply.started":"2023-11-13T18:31:12.403189Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(76460, 9)\n"]}],"source":["print(data.shape)"]},{"cell_type":"markdown","metadata":{},"source":["Lets get only the first 10% of the data to speed up the training process."]},{"cell_type":"code","execution_count":697,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:12.411719Z","iopub.status.busy":"2023-11-13T18:31:12.411338Z","iopub.status.idle":"2023-11-13T18:31:12.423165Z","shell.execute_reply":"2023-11-13T18:31:12.421661Z","shell.execute_reply.started":"2023-11-13T18:31:12.411686Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set shape:  (30584, 9)\n","Validation set shape:  (7646, 9)\n"]}],"source":["num_samples = len(data)\n","training_set = data[:int(num_samples*0.4)]\n","# Validation is the last 10% of samples\n","validation_set = data[int(num_samples*0.9):]\n","# reset index in both dataframes\n","training_set.reset_index(drop=True, inplace=True)\n","validation_set.reset_index(drop=True, inplace=True)\n","# print shapes\n","print('Training set shape: ', training_set.shape)\n","print('Validation set shape: ', validation_set.shape)"]},{"cell_type":"markdown","metadata":{},"source":["Proportion of the data that will be used for training and testing."]},{"cell_type":"code","execution_count":698,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:12.426850Z","iopub.status.busy":"2023-11-13T18:31:12.426458Z","iopub.status.idle":"2023-11-13T18:31:12.433508Z","shell.execute_reply":"2023-11-13T18:31:12.432617Z","shell.execute_reply.started":"2023-11-13T18:31:12.426821Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Proportion of training set: 40.0%\n","Proportion of validation set: 10.0%\n"]}],"source":["print(f\"Proportion of training set: {training_set.shape[0]/len(data)*100}%\")\n","print(f\"Proportion of validation set: {validation_set.shape[0]/len(data)*100}%\")"]},{"cell_type":"code","execution_count":699,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:12.434818Z","iopub.status.busy":"2023-11-13T18:31:12.434484Z","iopub.status.idle":"2023-11-13T18:31:12.456201Z","shell.execute_reply":"2023-11-13T18:31:12.455008Z","shell.execute_reply.started":"2023-11-13T18:31:12.434787Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["     alpha      beta     gamma  remaining_energy  alive_nodes  \\\n","0  0.12304  7.944358  5.167098          5.118514           99   \n","1  0.12304  7.944358  5.167098          5.066551           99   \n","2  0.12304  7.944358  5.167098          5.016569           99   \n","3  0.12304  7.944358  5.167098          4.966186           99   \n","4  0.12304  7.944358  5.167098          4.917782           99   \n","\n","          cluster_heads                                      energy_levels  \\\n","0       [0, 0, 0, 0, 0]  [0.0698517842813034, 0.06605397164431653, 0.00...   \n","1   [2, 22, 50, 77, 86]  [0.05932810428130321, 0.06567921164431653, 0.0...   \n","2   [2, 22, 50, 77, 86]  [0.04882442428130327, 0.06532445164431654, 0.0...   \n","3  [22, 53, 58, 77, 86]  [0.04860234428130327, 0.06496485164431653, 0.0...   \n","4  [22, 53, 58, 77, 86]  [0.04840026428130327, 0.06462525164431654, 0.0...   \n","\n","                                 dst_to_cluster_head  \\\n","0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n","1  [0.0, 62.20128616033595, 42.5440947723653, 65....   \n","2  [0.0, 62.20128616033595, 42.5440947723653, 65....   \n","3  [7.211102550927978, 59.07622195096772, 40.0249...   \n","4  [7.211102550927978, 59.07622195096772, 40.0249...   \n","\n","                                          membership  \n","0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","1  [2, 50, 22, 2, 2, 2, 86, 2, 22, 2, 22, 2, 50, ...  \n","2  [2, 50, 22, 2, 2, 2, 86, 2, 22, 2, 22, 2, 50, ...  \n","3  [53, 58, 53, 53, 53, 53, 86, 53, 53, 53, 22, 5...  \n","4  [53, 58, 53, 53, 53, 53, 86, 53, 53, 53, 22, 5...  ,(30584, 9)\n","      alpha      beta     gamma  remaining_energy  alive_nodes  \\\n","0  6.396204  3.317884  2.399387          2.845431           89   \n","1  6.396204  3.317884  2.399387          2.801312           89   \n","2  6.396204  3.317884  2.399387          2.757202           89   \n","3  6.396204  3.317884  2.399387          2.713494           89   \n","4  6.396204  3.317884  2.399387          2.670671           89   \n","\n","          cluster_heads                                      energy_levels  \\\n","0  [33, 49, 56, 70, 88]  [0.03218247005397702, 0.02710971871302542, 0.0...   \n","1     [2, 4, 8, 25, 72]  [0.02885879005397704, 0.026880038713025422, 0....   \n","2    [4, 8, 72, 78, 88]  [0.02863811005397704, 0.026650358713025422, 0....   \n","3   [4, 22, 58, 59, 72]  [0.02841523005397704, 0.026420678713025423, 0....   \n","4  [17, 25, 30, 78, 91]  [0.02819263005397704, 0.026159678713025422, 0....   \n","\n","                                 dst_to_cluster_head  \\\n","0  [4.123105625617661, 23.853720883753127, 12.649...   \n","1  [0.0, 15.556349186104045, 0.0, 12.529964086141...   \n","2  [4.123105625617661, 15.556349186104045, 0.0, 1...   \n","3  [8.48528137423857, 15.556349186104045, 0.0, 12...   \n","4  [8.06225774829855, 32.01562118716424, 28.30194...   \n","\n","                                          membership  \n","0  [88, 33, 70, 49, 88, 49, 33, 0, 70, 49, 70, 49...  \n","1  [2, 72, 4, 72, 2, 72, 8, 0, 4, 4, 4, 72, 8, 2,...  \n","2  [88, 72, 4, 72, 88, 72, 8, 0, 4, 4, 4, 72, 8, ...  \n","3  [22, 72, 4, 72, 22, 72, 58, 0, 4, 4, 4, 72, 58...  \n","4  [25, 17, 91, 91, 25, 91, 17, 0, 91, 91, 78, 91...  ,(7646, 9)\n"]}],"source":["print(f\"{training_set.head()},{training_set.shape}\")\n","print(f\"{validation_set.head()},{validation_set.shape}\")"]},{"cell_type":"code","execution_count":700,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:12.457733Z","iopub.status.busy":"2023-11-13T18:31:12.457383Z","iopub.status.idle":"2023-11-13T18:31:43.492244Z","shell.execute_reply":"2023-11-13T18:31:43.491121Z","shell.execute_reply.started":"2023-11-13T18:31:12.457702Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing sequence: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 30579/30584 [00:14<00:00, 2161.94it/s]\n","Processing sequence: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 7641/7646 [00:03<00:00, 2278.18it/s]\n"]}],"source":["def split_sequence(sequence, n_steps):\n","    num_samples = len(sequence)\n","    x = []\n","    y = []\n","\n","    alpha_values = sequence['alpha'].astype(float)\n","    beta_values = sequence['beta'].astype(float)\n","    gamma_values = sequence['gamma'].astype(float)\n","    remaining_energy_values = sequence['remaining_energy']\n","    alive_nodes_values = sequence['alive_nodes']\n","    energy_levels_values = np.array(\n","        [eval(x) for x in sequence['energy_levels']])\n","    # print shape of energy levels\n","    dst_to_cluster_head_values = np.array(\n","        [eval(x) for x in sequence['dst_to_cluster_head']])\n","    membership_values = np.array([eval(x) for x in sequence['membership']])\n","    cluster_heads = sequence['cluster_heads']\n","    cluster_heads = np.array([eval(x) for x in cluster_heads])\n","\n","    for i in tqdm(range(num_samples), desc=\"Processing sequence\"):\n","        alpha_val, beta_val, gamma_val = alpha_values[i], beta_values[i], gamma_values[i]\n","        remaining_energy = remaining_energy_values[i:i+n_steps].values\n","        alive_nodes = alive_nodes_values[i:i+n_steps].values\n","        energy_levels = energy_levels_values[i]\n","        dst_to_cluster_head = dst_to_cluster_head_values[i]\n","        membership = membership_values[i]\n","        end_ix = i + n_steps\n","\n","        if end_ix > num_samples - 1:\n","            break\n","\n","        chs, seq_y = cluster_heads[i:end_ix], cluster_heads[end_ix]\n","        chs = [item for sublist in chs for item in sublist]\n","        # remaining_energy = [item for sublist in remaining_energy for item in sublist]\n","        # alive_nodes = [item for sublist in alive_nodes for item in sublist]\n","        # seq_x = [alpha_val, beta_val, gamma_val, remaining_energy, alive_nodes]\n","        seq_x = [alpha_val/10, beta_val/10, gamma_val/10]\n","        assert all(\n","            x <= 1 and x >= -1 for x in seq_x), f\"Incorrect values of alpha, beta or gamma: {seq_x}\"\n","        # Normalize remaining energy dividing by 10\n","        remaining_energy = [x/10 for x in remaining_energy]\n","        assert all(\n","            x <= 1 and x >= -1 for x in remaining_energy), f\"Incorrect values of remaining energy: {remaining_energy}\"\n","        seq_x.extend(remaining_energy)\n","        # Normalize alive nodes dividing by 100\n","        alive_nodes = [x/100 for x in alive_nodes]\n","        assert all(\n","            x <= 1 and x >= -1 for x in alive_nodes), f\"Incorrect values of alive nodes: {alive_nodes}\"\n","        seq_x.extend(alive_nodes)\n","        # Normalize energy levels dividing by 5\n","        energy_levels = [x/5 for x in energy_levels]\n","        assert all(\n","            x <= 1 and x >= -1 for x in energy_levels), f\"Incorrect values of energy levels: {energy_levels}\"\n","        seq_x.extend(energy_levels)\n","        # Normalize distance to cluster head dividing by 100\n","        dst_to_cluster_head = [x/200 for x in dst_to_cluster_head]\n","        assert all(\n","            x <= 1 and x >= -1 for x in dst_to_cluster_head), f\"Incorrect values of distance to cluster head: {dst_to_cluster_head}\"\n","        seq_x.extend(dst_to_cluster_head)\n","        # Normalize membership dividing by 100\n","        membership = [x/100 for x in membership]\n","        assert all(\n","            x <= 1 and x >= -1 for x in membership), f\"Incorrect values of membership: {membership}\"\n","        seq_x.extend(membership)\n","        # Normalize cluster heads dividing by 100\n","        chs = [x/100 for x in chs]\n","        assert all(x <= 1 and x >= -\n","                   1 for x in chs), f\"Incorrect values of cluster heads: {chs}\"\n","        seq_x.extend(chs)\n","\n","        if (alpha_values[end_ix] != alpha_val) or (beta_values[end_ix] != beta_val) or (gamma_values[end_ix] != gamma_val):\n","            continue\n","\n","        x.append(seq_x)\n","        y.append(seq_y)\n","\n","    return np.array(x), np.array(y)\n","\n","\n","n_steps = 5\n","x_train, y_train = split_sequence(training_set, n_steps)\n","y_train = np.eye(101)[y_train.astype('int')]\n","x_val, y_val = split_sequence(validation_set, n_steps)\n","y_val = np.eye(101)[y_val.astype('int')]"]},{"cell_type":"code","execution_count":701,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:43.495202Z","iopub.status.busy":"2023-11-13T18:31:43.494201Z","iopub.status.idle":"2023-11-13T18:31:43.501438Z","shell.execute_reply":"2023-11-13T18:31:43.499866Z","shell.execute_reply.started":"2023-11-13T18:31:43.495166Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(29384, 335)\n","(29384, 5, 101)\n"]}],"source":["# print(x_train)\n","print(x_train.shape)\n","# print(y_train)\n","print(y_train.shape)"]},{"cell_type":"markdown","metadata":{},"source":["Create the dataset class."]},{"cell_type":"code","execution_count":702,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:43.503171Z","iopub.status.busy":"2023-11-13T18:31:43.502808Z","iopub.status.idle":"2023-11-13T18:31:43.512853Z","shell.execute_reply":"2023-11-13T18:31:43.511732Z","shell.execute_reply.started":"2023-11-13T18:31:43.503138Z"},"trusted":true},"outputs":[],"source":["class ClusterHeadDataset(Dataset):\n","    def __init__(self, x, y):\n","        self.X = torch.from_numpy(x.astype(np.float32))\n","        self.y = torch.from_numpy(y.astype(np.float32))\n","        self.len = x.shape[0]\n","\n","    def __len__(self):\n","        return self.len\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","    # Support batching\n","    def collate_fn(self, batch):\n","        X = torch.stack([x[0] for x in batch])\n","        y = torch.stack([x[1] for x in batch])\n","        return X, y"]},{"cell_type":"markdown","metadata":{},"source":["Create the network architecture."]},{"cell_type":"code","execution_count":703,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:43.514661Z","iopub.status.busy":"2023-11-13T18:31:43.514301Z","iopub.status.idle":"2023-11-13T18:31:43.528177Z","shell.execute_reply":"2023-11-13T18:31:43.526867Z","shell.execute_reply.started":"2023-11-13T18:31:43.514633Z"},"trusted":true},"outputs":[],"source":["class ForecastCCH(nn.Module):\n","    def __init__(self):\n","        super(ForecastCCH, self).__init__()\n","        self.fc1 = nn.Linear(335, 800)\n","        self.drop1 = nn.Dropout(0.2)\n","        self.fc2 = nn.Linear(800, 800)\n","        self.drop2 = nn.Dropout(0.4)\n","        self.fc3 = nn.Linear(800, 101*5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.drop1(x)\n","        x = self.fc2(x)\n","        x = self.relu(x)\n","        x = self.drop2(x)\n","        x = self.fc3(x)\n","        return x.view(-1, 5, 101)"]},{"cell_type":"code","execution_count":704,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:43.529958Z","iopub.status.busy":"2023-11-13T18:31:43.529628Z","iopub.status.idle":"2023-11-13T18:31:43.698779Z","shell.execute_reply":"2023-11-13T18:31:43.697725Z","shell.execute_reply.started":"2023-11-13T18:31:43.529931Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = ForecastCCH().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n","criterion = nn.CrossEntropyLoss()\n","rl_scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"]},{"cell_type":"markdown","metadata":{},"source":["Create the dataset objects."]},{"cell_type":"code","execution_count":705,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:43.700426Z","iopub.status.busy":"2023-11-13T18:31:43.700042Z","iopub.status.idle":"2023-11-13T18:31:43.733724Z","shell.execute_reply":"2023-11-13T18:31:43.732500Z","shell.execute_reply.started":"2023-11-13T18:31:43.700395Z"},"trusted":true},"outputs":[],"source":["train = ClusterHeadDataset(x_train, y_train)\n","valid = ClusterHeadDataset(x_val, y_val)\n","train_loader = DataLoader(train, batch_size=2000, shuffle=False)\n","valid_loader = DataLoader(valid, batch_size=2000, shuffle=False)"]},{"cell_type":"code","execution_count":706,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:43.737004Z","iopub.status.busy":"2023-11-13T18:31:43.736607Z","iopub.status.idle":"2023-11-13T18:31:43.748311Z","shell.execute_reply":"2023-11-13T18:31:43.747143Z","shell.execute_reply.started":"2023-11-13T18:31:43.736969Z"},"trusted":true},"outputs":[],"source":["train_losses = []\n","valid_losses = []\n","\n","\n","def Train():\n","    running_loss = .0\n","\n","    model.train()\n","\n","    # Wrap the data loader with tqdm to add a progress bar\n","    for idx, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n","        # print(inputs.shape)\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        preds = model(inputs.float())\n","        loss = criterion(preds, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss\n","\n","    train_loss = running_loss / len(train_loader)\n","    train_losses.append(train_loss.detach().numpy())\n","\n","    print(f'train_loss {train_loss}')\n","\n","\n","def Valid():\n","    running_loss = .0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for idx, (inputs, labels) in enumerate(valid_loader):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","            preds = model(inputs.float())\n","            loss = criterion(preds, labels)\n","            running_loss += loss\n","\n","        valid_loss = running_loss/len(valid_loader)\n","        valid_losses.append(valid_loss.detach().numpy())\n","        print(f'valid_loss {valid_loss}')"]},{"cell_type":"code","execution_count":707,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:43.752645Z","iopub.status.busy":"2023-11-13T18:31:43.752290Z","iopub.status.idle":"2023-11-13T18:31:43.760888Z","shell.execute_reply":"2023-11-13T18:31:43.759799Z","shell.execute_reply.started":"2023-11-13T18:31:43.752610Z"},"trusted":true},"outputs":[],"source":["def test_predicted():\n","    model.eval()\n","    avg_accuracy = []\n","    losses = []\n","    with torch.no_grad():\n","        for idx, (inputs, labels) in enumerate(valid_loader):\n","            # print(f\"inputs: {inputs}, shape: {inputs.shape}\")\n","            # print(f\"labels: {labels}, shape: {labels.shape}\")\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","            preds = model(inputs.float())\n","            loss = criterion(preds, labels)\n","            losses.append(loss.item())\n","            y = torch.argmax(labels, dim=2)\n","            output = torch.argmax(preds, dim=2)\n","            correct = (output == y).sum().item()\n","            total = np.product(y.shape)\n","            avg_accuracy.append(correct/total*100)\n","    print(\n","        f\"Average loss: {np.mean(losses)}\")\n","    print(\n","        f\"Average accuracy: {np.mean(avg_accuracy)}%\")\n","    print"]},{"cell_type":"code","execution_count":708,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T18:31:43.762533Z","iopub.status.busy":"2023-11-13T18:31:43.762214Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["epochs 1/1000\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [01:51<00:00,  7.43s/it]\n"]},{"name":"stdout","output_type":"stream","text":["train_loss 0.10068816691637039\n","valid_loss 0.05699867010116577\n","Average loss: 0.0569986691698432\n","Average accuracy: 1.7031133482475764%\n","epochs 2/1000\n"]},{"name":"stderr","output_type":"stream","text":["Training:  20%|████████████████████████████████▍                                                                                                                                 | 3/15 [00:38<02:35, 12.94s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb Cell 22\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb#Y233sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb#Y233sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mepochs \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,epochs))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb#Y233sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     Train()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb#Y233sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     rl_scheduler\u001b[39m.\u001b[39mstep()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb#Y233sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     Valid()\n","\u001b[1;32m/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb Cell 22\u001b[0m line \u001b[0;36mTrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb#Y233sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m preds \u001b[39m=\u001b[39m model(inputs\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb#Y233sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(preds, labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb#Y233sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb#Y233sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fernando/PyNetSim/tutorials/surrogate/ch_training.ipynb#Y233sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["epochs = 1000\n","for epoch in range(epochs):\n","    print('epochs {}/{}'.format(epoch+1,epochs))\n","    Train()\n","    rl_scheduler.step()\n","    Valid()\n","    if epoch % 5 == 0:\n","        test_predicted()\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["valid_loader = DataLoader(valid, batch_size=1, shuffle=False)\n","test_predicted()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
